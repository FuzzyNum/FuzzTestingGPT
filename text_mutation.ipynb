{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data:dict):\n",
    "        self._data=data\n",
    "        self._original=data\n",
    "    def reset_data(self):\n",
    "        self.data=self.original\n",
    "    def keys(self):\n",
    "        return self._data.keys()\n",
    "    def values(self):\n",
    "        return self._data.values()\n",
    "    def items(self):\n",
    "        return self._data.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_labels={0:\"random\",1:\"single_word_syn\",2:\"n_word_syn\",3:\"single_word_ant\",4:\"n_word_ant\",5:\"misspell\",6:\"reorder\",7:\"addition\",8:\"deletion\"}\n",
    "strategy_ids={\"random\":0,\"single_word_syn\":1,\"n_word_syn\":2,\"single_word_ant\":3,\"n_word_ant\":4,\"misspell\":5,\"reorder\":6,\"addition\":7,\"deletion\":8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MutagenDataset(Dataset):\n",
    "    def __init__(self, data:dict, operator:Operator, mutations=[], strategy=\"random\"):\n",
    "        super().__init__(data)\n",
    "        self._mutations=mutations\n",
    "        self._strategy=strategy\n",
    "        self._stratid=strategy_ids[strategy]\n",
    "        self._operator=operator\n",
    "    def reset_data(self):\n",
    "        super().reset_data()\n",
    "        self._mutations=[]\n",
    "    def appendMutations(self,mutation:list):\n",
    "        self._mutations.append(mutation)\n",
    "    def computeLevenshtein(self):\n",
    "        distances=[]\n",
    "        for i in range(0,len(self._data)):\n",
    "            distances.append(lev(self._original[i],self._data[i]))\n",
    "        average_dist=sum(distances)/len(self._data)\n",
    "        return distances,average_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator:\n",
    "    def __init__(self,stratid):\n",
    "        self.strategy=strategy_ids[stratid]\n",
    "    def mutate(self,data:dict):\n",
    "        if self.strategy==0:\n",
    "            pass\n",
    "        elif self.strategy==1:\n",
    "            pass\n",
    "        elif self.strategy==2:\n",
    "            pass\n",
    "        elif self.strategy==3:\n",
    "            pass\n",
    "        elif self.strategy==4:\n",
    "            pass\n",
    "        elif self.strategy==5:\n",
    "            pass\n",
    "        elif self.strategy==6:\n",
    "            pass\n",
    "        elif self.strategy==7:\n",
    "            pass\n",
    "        elif self.strategy==8:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def replaceSubString(dataset : Dataset, substring, replacement, count=-1):\n",
    "    for key, texts in dataset.items():\n",
    "        textsBuffer = []\n",
    "        for text in texts:\n",
    "            texts : str\n",
    "            textsBuffer.append(text.replace(substring, replacement, count))\n",
    "        dataset[key] = textsBuffer\n",
    "        \n",
    "import re\n",
    "def replaceWords(dataset : Dataset, word_list : dict, count=1):\n",
    "    for key, texts in dataset.items():\n",
    "        textsBuffer = []\n",
    "        for text in texts:\n",
    "            text : str\n",
    "            text = text.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\")\n",
    "            amountToReplace = int(count / 2)\n",
    "            for word, replacement in word_list.items():\n",
    "                print(\".\" + str(amountToReplace))\n",
    "                (text, numReplaced) = re.subn(word, replacement, text, amountToReplace)\n",
    "                amountToReplace -= numReplaced\n",
    "                print(str(amountToReplace))\n",
    "                if amountToReplace <= 0:\n",
    "                    break\n",
    "            textsBuffer.append(text)\n",
    "        dataset[key] = textsBuffer\n",
    "\n",
    "import random\n",
    "def replaceWordsByDoubleList(dataset : Dataset, word_list : list, count=1):\n",
    "    for key, texts in dataset.items():\n",
    "        textsBuffer = []\n",
    "        for text in texts:\n",
    "            text : str\n",
    "            text = text.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\")\n",
    "            amountToReplace = count\n",
    "            words = text.split(\" \")\n",
    "            for word in words:\n",
    "                if(word in word_list):\n",
    "                    (text, numReplaced) = re.subn(word, random.choice(word_list), text, amountToReplace)\n",
    "                    amountToReplace -= numReplaced\n",
    "                if amountToReplace <= 0:\n",
    "                    break\n",
    "            textsBuffer.append(text)\n",
    "        dataset[key] = textsBuffer\n",
    "\n",
    "import requests, json\n",
    "def getSynonymAPI(word) -> str:\n",
    "    with open(\"./mutation_data/synonyms.json\", \"r+\") as f:\n",
    "        local_synonyms = json.load(f)\n",
    "        if word in local_synonyms:\n",
    "            if len(local_synonyms[word]) is 0:\n",
    "                return word\n",
    "            return local_synonyms[word][0]\n",
    "        url = f\"https://wordsapiv1.p.rapidapi.com/words/{word}/synonyms\"\n",
    "\n",
    "        headers = {\n",
    "            \"X-RapidAPI-Key\": \"41b9c2ee17msh295225a18398362p1c732cjsn4afb01c0b61f\",\n",
    "            \"X-RapidAPI-Host\": \"wordsapiv1.p.rapidapi.com\"\n",
    "        }\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers)\n",
    "        print(dict(response.json()))\n",
    "        synonyms=[]\n",
    "        try:\n",
    "            synonyms = response.json()['synonyms']\n",
    "        except KeyError:\n",
    "            synonyms = []\n",
    "        local_synonyms[word] = synonyms\n",
    "        f.seek(0)\n",
    "        f.write((json.dumps(local_synonyms)))\n",
    "        f.truncate()\n",
    "        if len(synonyms) is 0:\n",
    "            return word\n",
    "        return synonyms\n",
    "\n",
    "def getAntonymAPI(word) -> str:\n",
    "    with open(\"./mutation_data/antonyms.json\", \"r+\") as f:\n",
    "        local_antonyms = json.load(f)\n",
    "        if word in local_antonyms:\n",
    "            if len(local_antonyms[word]) is 0:\n",
    "                return word\n",
    "            return local_antonyms[word][0]\n",
    "        url = f\"https://wordsapiv1.p.rapidapi.com/words/{word}/antonyms\"\n",
    "\n",
    "        headers = {\n",
    "            \"X-RapidAPI-Key\": \"41b9c2ee17msh295225a18398362p1c732cjsn4afb01c0b61f\",\n",
    "            \"X-RapidAPI-Host\": \"wordsapiv1.p.rapidapi.com\"\n",
    "        }\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers)\n",
    "        antonyms = []\n",
    "        try:\n",
    "            antonyms = response.json()['antonyms']\n",
    "        except KeyError:\n",
    "            antonyms = []\n",
    "        local_antonyms[word] = antonyms\n",
    "        f.seek(0)\n",
    "        f.write((json.dumps(local_antonyms)))\n",
    "        f.truncate()\n",
    "        if len(antonyms) is 0:\n",
    "            return word\n",
    "        return antonyms[0]\n",
    "\n",
    "\n",
    "\n",
    "#FromAPI\n",
    "def getRandomWordAPI() -> str:\n",
    "    url = \"https://wordsapiv1.p.rapidapi.com/words/\"\n",
    "    querystring = {\"random\":\"true\"}\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": \"41b9c2ee17msh295225a18398362p1c732cjsn4afb01c0b61f\",\n",
    "        \"X-RapidAPI-Host\": \"wordsapiv1.p.rapidapi.com\"\n",
    "    }\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    return response.json()[\"word\"]\n",
    "\n",
    "#From json files\n",
    "import random\n",
    "def getRandomWordJSON() -> str:\n",
    "    with open(\"./mutation_data/random_word.json\", \"r\") as file:\n",
    "        words = dict(json.load(file))['word']\n",
    "        words : list\n",
    "        return random.choice(words)\n",
    "\n",
    "def getRandomVerbJSON() -> str:\n",
    "    with open(\"./mutation_data/random_verbs.json\", \"r\") as file:\n",
    "        verbs = dict(json.load(file))['verb']\n",
    "        verbs : list\n",
    "        return random.choice(verbs)\n",
    "\n",
    "\n",
    "def getRandomAdverbJSON() -> str:\n",
    "    with open(\"./mutation_data/random_adverbs.json\", \"r\") as file:\n",
    "        adverbs = dict(json.load(file))['adverb']\n",
    "        adverbs : list\n",
    "        return random.choice(adverbs)\n",
    "\n",
    "def getRandomAdjectiveJSON() -> str:\n",
    "    with open(\"./mutation_data/random_adjectivea.json\", \"r\") as file:\n",
    "        adjectives = dict(json.load(file))['adjective']\n",
    "        adjectives : list\n",
    "        return random.choice(adjectives)\n",
    "\n",
    "#TODO: Might be too large a set of misspellings\n",
    "def getMisspellListJSON() -> dict:\n",
    "    with open(\"./mutation_data/misspellings.json\", \"r\") as file:\n",
    "        misspellings = dict(json.load(file))\n",
    "        actualMispells = {}\n",
    "        for word, missSpells in misspellings.items():\n",
    "            if len(missSpells) > 0:\n",
    "                actualMispells[word] = random.choice(missSpells)\n",
    "        return actualMispells\n",
    "\n",
    "def populateRandomWord(count = 1):\n",
    "    with open(\"./mutation_data/random_word.json\", \"r+\") as f:\n",
    "        local_words = json.load(f)\n",
    "        if \"word\" not in local_words:\n",
    "            local_words = {\"word\" : []}\n",
    "        for i in range(0, count):\n",
    "            word = getRandomWordAPI()\n",
    "            if word in local_words[\"word\"]:\n",
    "                continue\n",
    "            local_words[\"word\"].append(word)\n",
    "        f.seek(0)\n",
    "        f.write((json.dumps(local_words)))\n",
    "        f.truncate()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mutation_miniframework.base_mutators import *\n",
    "\n",
    "#Mutation Operators\n",
    "'''\n",
    "Saves new file output with added functional name additions\n",
    "'''\n",
    "\n",
    "\n",
    "def replaceFromDictionary(dataset : Dataset, word_list : dict, mutation=\"misspell\", word_change_limit=1):\n",
    "    replaceWords(dataset, word_list, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "'''\n",
    "Takes an article and adds spaces between to replace\n",
    "'''\n",
    "def replaceArticles(dataset : Dataset, articles : dict, mutation=\"articleSub\", word_change_limit=1):\n",
    "    replaceWords(dataset, articles, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "def replaceLetters(dataset : Dataset, articles : dict, mutation=\"letterReplace\", word_change_limit=1):\n",
    "    replaceWords(dataset, articles, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "def replaceSynonyms(dataset : Dataset, words_to_replace : list, mutation=\"synonymSub\", word_change_limit=1):\n",
    "    word_list = {}\n",
    "    for word in words_to_replace:\n",
    "        word_list[word] = getSynonymAPI(word)\n",
    "    replaceWords(dataset, word_list, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "def replaceInTextsRandomSynonymAPI(dataset : Dataset, mutation=\"randSynonym\", word_change_limit=1):\n",
    "    word_list = {}\n",
    "    for key, texts in dataset.items():\n",
    "        for word in texts.split(\" \"):\n",
    "            word_list[word] = getSynonymAPI(word)\n",
    "    replaceWords(dataset, word_list, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "def replaceInTextsAntonymAPI(dataset : Dataset, words_to_replace : list, mutation=\"antonym\", word_change_limit=1):\n",
    "    word_list = {}\n",
    "    for word in words_to_replace:\n",
    "        word_list[word] = getAntonymAPI(word)\n",
    "    replaceWords(dataset, word_list, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "def replaceInTextsRandomAntonymAPI(dataset : Dataset, mutation=\"randAntonym\", word_change_limit=1):\n",
    "    word_list = {}\n",
    "    for key, texts in dataset.items():\n",
    "        for word in texts.split(\" \"):\n",
    "            word_list[word] = getAntonymAPI(word)\n",
    "    replaceWords(dataset, word_list, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "'''\n",
    "Replaces an adjective with another\n",
    "'''\n",
    "def replaceInTextsRandomAdjective(dataset : Dataset, word_change_limit=1):\n",
    "    pass\n",
    "\n",
    "'''\n",
    "Replaces a verb with another\n",
    "'''\n",
    "def replaceInTextsRandomVerb(dataset : Dataset, word_change_limit=1):\n",
    "    pass\n",
    "\n",
    "def removeStartingArticles(dataset : Dataset):\n",
    "    for key, texts in dataset.items():\n",
    "        textsBuffer = []\n",
    "        for text in texts:\n",
    "            text : str\n",
    "            text = text.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\")\n",
    "            wordsList = text.split(\" \")\n",
    "            if wordsList[0].lower() == \"a\" or wordsList[0].lower() == \"the\" or wordsList[0].lower() == \"an\":\n",
    "                wordsList = wordsList[1:]\n",
    "            text = ' '.join(wordsList)\n",
    "            textsBuffer.append(text)\n",
    "        dataset[key] = textsBuffer\n",
    "\n",
    "def deleteRandomArticle(dataset : Dataset, articles : list, mutation=\"delArticles\", word_change_limit=1):\n",
    "    word_list = {}\n",
    "    for article in articles:\n",
    "        word_list[article] = \" \"\n",
    "    replaceWords(dataset, word_list, word_change_limit)\n",
    "    removeStartingArticles(dataset)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "def replaceWordListWithRandomSelf(dataset : Dataset, random_words : list, mutation=\"randWord\", word_change_limit=1):\n",
    "    replaceWordsByDoubleList(dataset, random_words, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
