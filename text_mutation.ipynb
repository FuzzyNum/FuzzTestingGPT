{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    '''\n",
    "    Wraps the Python Dictionary built-in class with some extra functions\n",
    "    -Saves original dataset for reverting\n",
    "    -Saves a root directory for the dataset for re-use\n",
    "    -Unique file name saving per dataset\n",
    "    Dictionary format\n",
    "    {\n",
    "        Unique_ID: [TEXT1, TEXT2, ETC],\n",
    "        Unique_ID: [TEXT1, TEXT2, ETC],\n",
    "        Unique_ID: [ETC]\n",
    "    }\n",
    "    '''\n",
    "    _data : dict\n",
    "    _original_data : dict\n",
    "    _root_dir = \".\"\n",
    "    # List of strings to add to file name\n",
    "    _mutations: list\n",
    "\n",
    "    def __init__(self, data: dict, mutations: list):\n",
    "        self._data = data\n",
    "        self._original_data = data\n",
    "        self._mutations = mutations\n",
    "\n",
    "    def resetData(self):\n",
    "        self._data = self._original_data\n",
    "        self._mutations = []\n",
    "\n",
    "    def saveDataMutation(self, mutation_append: list):\n",
    "        self._mutations.append(mutation_append)\n",
    "\n",
    "    def _determineFileName(self) -> str:\n",
    "        base_name = \"\"\n",
    "        for mutation in self._mutations:\n",
    "            base_name = base_name + mutation\n",
    "        file_name = base_name + \".json\"\n",
    "        files_in_directory = os.listdir(self._root_dir)\n",
    "        for i in range(1, 10_000):\n",
    "            if (file_name not in files_in_directory):\n",
    "                break\n",
    "            if (file_name in files_in_directory):\n",
    "                file_name = base_name + str(i) + \".json\"\n",
    "        return self._root_dir + file_name\n",
    "\n",
    "    def setRootDir(self, root: str):\n",
    "        self._root_dir = root\n",
    "\n",
    "    def saveToFile(self):\n",
    "        with open(self._determineFileName(), \"w\") as outfile:\n",
    "            json.dump(self._data, outfile)\n",
    "\n",
    "    #Behave as a dictionary\n",
    "    def keys(self) -> list:\n",
    "        return self._data.keys()\n",
    "\n",
    "    def values(self) -> list:\n",
    "        return self._data.values()\n",
    "\n",
    "    def items(self) -> tuple:\n",
    "        return self._data.items()\n",
    "\n",
    "    #Operator overloads\n",
    "    def __str__(self):\n",
    "        return str(self._data)\n",
    "    def __setitem__(self, key, value):\n",
    "        self._data[key] = value\n",
    "    def __getitem__(self, key):\n",
    "        return self._data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m             textsBuffer\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[1;32m     43\u001b[0m         dataset[key] \u001b[38;5;241m=\u001b[39m textsBuffer\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetSynonymAPI\u001b[39m(word) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./mutation_data/synonyms.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "\n",
    "def replaceSubString(dataset : Dataset, substring, replacement, count=-1):\n",
    "    for key, texts in dataset.items():\n",
    "        textsBuffer = []\n",
    "        for text in texts:\n",
    "            texts : str\n",
    "            textsBuffer.append(text.replace(substring, replacement, count))\n",
    "        dataset[key] = textsBuffer\n",
    "        \n",
    "import re\n",
    "def replaceWords(dataset : Dataset, word_list : dict, count=1):\n",
    "    for key, texts in dataset.items():\n",
    "        textsBuffer = []\n",
    "        for text in texts:\n",
    "            text : str\n",
    "            text = text.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\")\n",
    "            amountToReplace = int(count / 2)\n",
    "            for word, replacement in word_list.items():\n",
    "                print(\".\" + str(amountToReplace))\n",
    "                (text, numReplaced) = re.subn(word, replacement, text, amountToReplace)\n",
    "                amountToReplace -= numReplaced\n",
    "                print(str(amountToReplace))\n",
    "                if amountToReplace <= 0:\n",
    "                    break\n",
    "            textsBuffer.append(text)\n",
    "        dataset[key] = textsBuffer\n",
    "\n",
    "import random\n",
    "def replaceWordsByDoubleList(dataset : Dataset, word_list : list, count=1):\n",
    "    for key, texts in dataset.items():\n",
    "        textsBuffer = []\n",
    "        for text in texts:\n",
    "            text : str\n",
    "            text = text.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\")\n",
    "            amountToReplace = count\n",
    "            words = text.split(\" \")\n",
    "            for word in words:\n",
    "                if(word in word_list):\n",
    "                    (text, numReplaced) = re.subn(word, random.choice(word_list), text, amountToReplace)\n",
    "                    amountToReplace -= numReplaced\n",
    "                if amountToReplace <= 0:\n",
    "                    break\n",
    "            textsBuffer.append(text)\n",
    "        dataset[key] = textsBuffer\n",
    "\n",
    "import requests, json\n",
    "def getSynonymAPI(word) -> str:\n",
    "    with open(\"./mutation_data/synonyms.json\", \"r+\") as f:\n",
    "        local_synonyms = json.load(f)\n",
    "        if word in local_synonyms:\n",
    "            if len(local_synonyms[word]) == 0:\n",
    "                return word\n",
    "            return local_synonyms[word][0]\n",
    "        url = f\"https://wordsapiv1.p.rapidapi.com/words/{word}/synonyms\"\n",
    "\n",
    "        headers = {\n",
    "            \"X-RapidAPI-Key\": \"41b9c2ee17msh295225a18398362p1c732cjsn4afb01c0b61f\",\n",
    "            \"X-RapidAPI-Host\": \"wordsapiv1.p.rapidapi.com\"\n",
    "        }\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers)\n",
    "        print(dict(response.json()))\n",
    "        synonyms=[]\n",
    "        try:\n",
    "            synonyms = response.json()['synonyms']\n",
    "        except KeyError:\n",
    "            synonyms = []\n",
    "        local_synonyms[word] = synonyms\n",
    "        f.seek(0)\n",
    "        f.write((json.dumps(local_synonyms)))\n",
    "        f.truncate()\n",
    "        if len(synonyms) == 0:\n",
    "            return word\n",
    "        return synonyms\n",
    "\n",
    "def getAntonymAPI(word) -> str:\n",
    "    with open(\"./mutation_data/antonyms.json\", \"r+\") as f:\n",
    "        local_antonyms = json.load(f)\n",
    "        if word in local_antonyms:\n",
    "            if len(local_antonyms[word]) == 0:\n",
    "                return word\n",
    "            return local_antonyms[word][0]\n",
    "        url = f\"https://wordsapiv1.p.rapidapi.com/words/{word}/antonyms\"\n",
    "\n",
    "        headers = {\n",
    "            \"X-RapidAPI-Key\": \"41b9c2ee17msh295225a18398362p1c732cjsn4afb01c0b61f\",\n",
    "            \"X-RapidAPI-Host\": \"wordsapiv1.p.rapidapi.com\"\n",
    "        }\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers)\n",
    "        antonyms = []\n",
    "        try:\n",
    "            antonyms = response.json()['antonyms']\n",
    "        except KeyError:\n",
    "            antonyms = []\n",
    "        local_antonyms[word] = antonyms\n",
    "        f.seek(0)\n",
    "        f.write((json.dumps(local_antonyms)))\n",
    "        f.truncate()\n",
    "        if len(antonyms) == 0:\n",
    "            return word\n",
    "        return antonyms[0]\n",
    "\n",
    "\n",
    "\n",
    "#FromAPI\n",
    "def getRandomWordAPI() -> str:\n",
    "    url = \"https://wordsapiv1.p.rapidapi.com/words/\"\n",
    "    querystring = {\"random\":\"true\"}\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": \"41b9c2ee17msh295225a18398362p1c732cjsn4afb01c0b61f\",\n",
    "        \"X-RapidAPI-Host\": \"wordsapiv1.p.rapidapi.com\"\n",
    "    }\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    return response.json()[\"word\"]\n",
    "\n",
    "#From json files\n",
    "import random\n",
    "def getRandomWordJSON() -> str:\n",
    "    with open(\"./mutation_data/random_word.json\", \"r\") as file:\n",
    "        words = dict(json.load(file))['word']\n",
    "        words : list\n",
    "        return random.choice(words)\n",
    "\n",
    "def getRandomVerbJSON() -> str:\n",
    "    with open(\"./mutation_data/random_verbs.json\", \"r\") as file:\n",
    "        verbs = dict(json.load(file))['verb']\n",
    "        verbs : list\n",
    "        return random.choice(verbs)\n",
    "\n",
    "\n",
    "def getRandomAdverbJSON() -> str:\n",
    "    with open(\"./mutation_data/random_adverbs.json\", \"r\") as file:\n",
    "        adverbs = dict(json.load(file))['adverb']\n",
    "        adverbs : list\n",
    "        return random.choice(adverbs)\n",
    "\n",
    "def getRandomAdjectiveJSON() -> str:\n",
    "    with open(\"./mutation_data/random_adjectivea.json\", \"r\") as file:\n",
    "        adjectives = dict(json.load(file))['adjective']\n",
    "        adjectives : list\n",
    "        return random.choice(adjectives)\n",
    "\n",
    "#TODO: Might be too large a set of misspellings\n",
    "def getMisspellListJSON() -> dict:\n",
    "    with open(\"./mutation_data/misspellings.json\", \"r\") as file:\n",
    "        misspellings = dict(json.load(file))\n",
    "        actualMispells = {}\n",
    "        for word, missSpells in misspellings.items():\n",
    "            if len(missSpells) > 0:\n",
    "                actualMispells[word] = random.choice(missSpells)\n",
    "        return actualMispells\n",
    "\n",
    "def populateRandomWord(count = 1):\n",
    "    with open(\"./mutation_data/random_word.json\", \"r+\") as f:\n",
    "        local_words = json.load(f)\n",
    "        if \"word\" not in local_words:\n",
    "            local_words = {\"word\" : []}\n",
    "        for i in range(0, count):\n",
    "            word = getRandomWordAPI()\n",
    "            if word in local_words[\"word\"]:\n",
    "                continue\n",
    "            local_words[\"word\"].append(word)\n",
    "        f.seek(0)\n",
    "        f.write((json.dumps(local_words)))\n",
    "        f.truncate()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def replaceFromDictionary(dataset : Dataset, word_list : dict, mutation=\"misspell\", word_change_limit=1):\n",
    "    replaceWords(dataset, word_list, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "'''\n",
    "Takes an article and adds spaces between to replace\n",
    "'''\n",
    "def replaceArticles(dataset : Dataset, articles : dict, mutation=\"articleSub\", word_change_limit=1):\n",
    "    replaceWords(dataset, articles, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "def replaceLetters(dataset : Dataset, articles : dict, mutation=\"letterReplace\", word_change_limit=1):\n",
    "    replaceWords(dataset, articles, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "def replaceSynonyms(dataset : Dataset, words_to_replace : list, mutation=\"synonymSub\", word_change_limit=1):\n",
    "    word_list = {}\n",
    "    for word in words_to_replace:\n",
    "        word_list[word] = getSynonymAPI(word)\n",
    "    replaceWords(dataset, word_list, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "def replaceInTextsRandomSynonymAPI(dataset : Dataset, mutation=\"randSynonym\", word_change_limit=1):\n",
    "    word_list = {}\n",
    "    for key, texts in dataset.items():\n",
    "        for word in texts.split(\" \"):\n",
    "            word_list[word] = getSynonymAPI(word)\n",
    "    replaceWords(dataset, word_list, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "def replaceInTextsAntonymAPI(dataset : Dataset, words_to_replace : list, mutation=\"antonym\", word_change_limit=1):\n",
    "    word_list = {}\n",
    "    for word in words_to_replace:\n",
    "        word_list[word] = getAntonymAPI(word)\n",
    "    replaceWords(dataset, word_list, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "def replaceInTextsRandomAntonymAPI(dataset : Dataset, mutation=\"randAntonym\", word_change_limit=1):\n",
    "    word_list = {}\n",
    "    for key, texts in dataset.items():\n",
    "        for word in texts.split(\" \"):\n",
    "            word_list[word] = getAntonymAPI(word)\n",
    "    replaceWords(dataset, word_list, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "'''\n",
    "Replaces an adjective with another\n",
    "'''\n",
    "def replaceInTextsRandomAdjective(dataset : Dataset, word_change_limit=1):\n",
    "    pass\n",
    "\n",
    "'''\n",
    "Replaces a verb with another\n",
    "'''\n",
    "def replaceInTextsRandomVerb(dataset : Dataset, word_change_limit=1):\n",
    "    pass\n",
    "\n",
    "def removeStartingArticles(dataset : Dataset):\n",
    "    for key, texts in dataset.items():\n",
    "        textsBuffer = []\n",
    "        for text in texts:\n",
    "            text : str\n",
    "            text = text.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\")\n",
    "            wordsList = text.split(\" \")\n",
    "            if wordsList[0].lower() == \"a\" or wordsList[0].lower() == \"the\" or wordsList[0].lower() == \"an\":\n",
    "                wordsList = wordsList[1:]\n",
    "            text = ' '.join(wordsList)\n",
    "            textsBuffer.append(text)\n",
    "        dataset[key] = textsBuffer\n",
    "\n",
    "def deleteRandomArticle(dataset : Dataset, articles : list, mutation=\"delArticles\", word_change_limit=1):\n",
    "    word_list = {}\n",
    "    for article in articles:\n",
    "        word_list[article] = \" \"\n",
    "    replaceWords(dataset, word_list, word_change_limit)\n",
    "    removeStartingArticles(dataset)\n",
    "    dataset.saveDataMutation(mutation)\n",
    "\n",
    "def replaceWordListWithRandomSelf(dataset : Dataset, random_words : list, mutation=\"randWord\", word_change_limit=1):\n",
    "    replaceWordsByDoubleList(dataset, random_words, word_change_limit)\n",
    "    dataset.saveDataMutation(mutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
